{
 "cells": [
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/MaxTechniche/BuildWeek2/main/model/'\n",
    "    !pip install category_encoders==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = 'model/'\n",
    "    \n",
    "top_1000 = 'top_1000.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH+top_1000)"
   ]
  },
  {
   "source": [
    "## Wrangling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genres(df):\n",
    "    \"\"\"Manual OneHotEncoding of genres\"\"\"\n",
    "    df = df.copy() \n",
    "    \n",
    "    # Grab genres\n",
    "    genres = set()\n",
    "    for item in df['Genres']:\n",
    "        item = item.lstrip(\"['\").rstrip(\"']\").replace(\"'\",\"\").split(', ')\n",
    "        for genre in item:\n",
    "            genres.add(genre)\n",
    "\n",
    "    # Create generic encoded genre columns\n",
    "    df[list(genres)] = 0\n",
    "        \n",
    "    # Set genre to 1 if contained\n",
    "    for i, item in zip(df.index, df['Genres']):\n",
    "        item = item.lstrip(\"['\").rstrip(\"']\").replace(\"'\",\"\").split(', ')\n",
    "        for genre in item:\n",
    "            df.at[i, genre] = 1\n",
    "        \n",
    "    return df\n",
    "\n",
    "def merge_certifications(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Create rating mapping\n",
    "    mapping = {\n",
    "        'TV-PG':'PG',\n",
    "        'TV-MA':'R',\n",
    "        'TV-14':'PG-13',\n",
    "        'M':'PG-13',\n",
    "        'GP':'PG',\n",
    "        'Unrated|Not Rated|Passed|Approved': np.NaN\n",
    "    }\n",
    "\n",
    "    # Apply rating mapping\n",
    "    df['Certification'] = df['Certification'].replace(mapping, regex=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def wrangle(df):\n",
    "    \"\"\"Basic wrangle. Calls other 'wrangle' functions. Drops unneccesarry/unwanted columns. Also feature engineering\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df = genres(df)\n",
    "    # df = merge_certifications(df)\n",
    "\n",
    "    df['Description Length'] = df['Description'].apply(lambda x: len(x))\n",
    "\n",
    "    df = df.drop(columns=['Placement', 'Genres', 'Description', 'Directors', 'stars', 'Title'])\n",
    "\n",
    "    return df\n",
    "\n",
    "df = wrangle(df)"
   ]
  },
  {
   "source": [
    "## Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Regression (RandomForestRegressor)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Runtime'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = df.copy()\n",
    "if reg_df[target].isna().sum():\n",
    "    reg_df = reg_df.dropna(subset=[target])\n",
    "reg_X = reg_df.drop(columns=target)\n",
    "reg_y = reg_df[target]\n",
    "\n",
    "reg_X_train, reg_X_val, reg_y_train, reg_y_val = train_test_split(reg_X, reg_y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "reg_pipeline = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    StandardScaler(),\n",
    "    SimpleImputer(),\n",
    "    Ridge(random_state=42, fit_intercept=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('ordinalencoder', OrdinalEncoder()),\n",
       "                                       ('standardscaler', StandardScaler()),\n",
       "                                       ('simpleimputer', SimpleImputer()),\n",
       "                                       ('ridge', Ridge(random_state=42))]),\n",
       "             n_jobs=6,\n",
       "             param_grid={'ridge__alpha': array([  0.1,   0.2,   0.3,   0.4,   0.5,   0.6,   0.7,   0.8,   0.9,\n",
       "         1. ,   1.1,   1.2,   1.3,   1.4,   1.5,   1.6,   1.7,   1.8,\n",
       "         1.9,   2. ,   2.1,   2.2,   2.3,   2.4,   2.5,   2.6,   2.7,\n",
       "         2.8,   2.9,   3. ,   3.1,   3...\n",
       "        93.7,  93.8,  93.9,  94. ,  94.1,  94.2,  94.3,  94.4,  94.5,\n",
       "        94.6,  94.7,  94.8,  94.9,  95. ,  95.1,  95.2,  95.3,  95.4,\n",
       "        95.5,  95.6,  95.7,  95.8,  95.9,  96. ,  96.1,  96.2,  96.3,\n",
       "        96.4,  96.5,  96.6,  96.7,  96.8,  96.9,  97. ,  97.1,  97.2,\n",
       "        97.3,  97.4,  97.5,  97.6,  97.7,  97.8,  97.9,  98. ,  98.1,\n",
       "        98.2,  98.3,  98.4,  98.5,  98.6,  98.7,  98.8,  98.9,  99. ,\n",
       "        99.1,  99.2,  99.3,  99.4,  99.5,  99.6,  99.7,  99.8,  99.9,\n",
       "       100. ]),\n",
       "                         'ridge__solver': ['lsqr', 'sparse_cg']})"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "reg_params = {\n",
    "    'ridge__alpha': np.arange(.1, 100.1, .1),\n",
    "    'ridge__solver': ['lsqr', 'sparse_cg']\n",
    "}\n",
    "\n",
    "reg = GridSearchCV(\n",
    "    reg_pipeline,\n",
    "    param_grid=reg_params,\n",
    "    n_jobs=6,\n",
    "    cv=5\n",
    ")\n",
    "reg.fit(reg_X_train, reg_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/ridge.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "dump(reg, 'model/ridge.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Baseline MAE: 20.224874999999997\nRegression MAE: 19.921241843136176\nRegression R2/Score: 0.2450102693355659\n"
     ]
    }
   ],
   "source": [
    "baseline = mean_absolute_error(reg_y_train, [reg_y_train.mean()]*len(reg_y_train))\n",
    "print('Baseline MAE:', baseline)\n",
    "print('Regression MAE:', mean_absolute_error(reg_y_val, reg.predict(reg_X_val))) # 8.9\n",
    "print('Regression R2/Score:', reg.score(reg_X_val, reg_y_val))\n"
   ]
  },
  {
   "source": [
    "Using a `RandomForestRegressor` would drop the MAE to around 9 but I have to use a linear model somewhere, so a 0.3 minute increased accuracy is what we've got.\n",
    "\n",
    "There's very little reason to determine the runtime of a movie, but if we can use features that we want to see, we can then determine how long the runtime should be to have a better chance at acheiving other things. (possibly)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Classification (LogisticRegression)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Certification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df = df.copy()\n",
    "if class_df[target].isna().sum():\n",
    "    class_df = class_df.dropna(subset=[target])\n",
    "class_X = class_df.drop(columns=target)\n",
    "class_y = class_df[target]\n",
    "\n",
    "class_X_train, class_X_val, class_y_train, class_y_val = train_test_split(class_X, class_y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pipeline = make_pipeline(\n",
    "    OrdinalEncoder(),\n",
    "    SimpleImputer(),\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier(n_jobs=6, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('ordinalencoder',\n",
       "                                              OrdinalEncoder()),\n",
       "                                             ('simpleimputer', SimpleImputer()),\n",
       "                                             ('standardscaler',\n",
       "                                              StandardScaler()),\n",
       "                                             ('randomforestclassifier',\n",
       "                                              RandomForestClassifier(n_jobs=6,\n",
       "                                                                     random_state=42))]),\n",
       "                   n_jobs=6,\n",
       "                   param_distributions={'randomforestclassifier__max_depth': range(8, 31, 2),\n",
       "                                        'randomforestclassifier__max_samples': array([0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 , 0.65, 0.7 ,\n",
       "       0.75, 0.8 ]),\n",
       "                                        'randomforestclassifier__n_estimators': range(100, 5001, 100)},\n",
       "                   random_state=42, verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "class_params = {\n",
    "    'randomforestclassifier__n_estimators': range(100, 5001, 100),\n",
    "    'randomforestclassifier__max_depth': range(8, 31, 2),\n",
    "    'randomforestclassifier__max_samples': np.arange(.2, .81, .05)\n",
    "}\n",
    "\n",
    "class_model = RandomizedSearchCV(\n",
    "    class_pipeline,\n",
    "    param_distributions=class_params,\n",
    "    n_jobs=6,\n",
    "    cv=5,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "class_model.fit(class_X_train, class_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['model/class.joblib']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "dump(class_model, 'model/class.joblib', compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Class Runtime Baseline Accuracy: 0.39847715736040606\n",
      "Class Runtime Model Accuracy: 0.5888324873096447\n"
     ]
    }
   ],
   "source": [
    "class_baseline = class_y_train.value_counts(normalize=True).max()\n",
    "\n",
    "print('Class Runtime Baseline Accuracy:', class_baseline)\n",
    "print('Class Runtime Model Accuracy:', class_model.score(class_X_val, class_y_val))\n"
   ]
  },
  {
   "source": [
    "Using the `merge_certifications` function generalizes the certifications of the group of movies. Leaving this out increases the accuracy of the `ridge` model but 'decreases' the accuracy of the `randomforestclassifier`. The reason for that is there's more for the ridge model to look at for determining runtime, but the classifier now has to determine from more than twice as many certifications."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Year', 'Certification', 'Rating', 'Metascore', 'Votes',\n",
       "       'USA Box Office', 'Adventure', 'Romance', 'Mystery', 'History',\n",
       "       'Family', 'Comedy', 'Film-Noir', 'Action', 'War', 'Crime', 'Sport',\n",
       "       'Western', 'Thriller', 'Music', 'Biography', 'Fantasy', 'Sci-Fi',\n",
       "       'Drama', 'Animation', 'Musical', 'Horror', 'Description Length'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "reg_X.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('BuildWeek2': pipenv)",
   "language": "python",
   "name": "python38564bitbuildweek2pipenvf79450b4995142a9a84972511960ad7b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}